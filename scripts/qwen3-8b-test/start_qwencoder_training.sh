#!/usr/bin/env bash

# ç®€å•çš„ QwenCoder SFT è®­ç»ƒå¯åŠ¨è„šæœ¬
set -euo pipefail

# å®šä¹‰è·¯å¾„
DATA_PATH="/volume/pt-train/users/wzhang/wjj-workspace/LightSFT-Qwen3-Humaneval/data/processed/sampled_data_20000.processed.npy"
PRETRAINED_MODEL="/volume/pt-train/models/Qwen2.5-7B"
OUTPUT_DIR="/volume/pt-train/users/wzhang/wjj-workspace/LightSFT-Qwen3-Humaneval/saves/qwen2.5-7b-sft"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
mkdir -p "${OUTPUT_DIR}"
mkdir -p ../../logs

# ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="../../logs/qwencoder_training_${TIMESTAMP}.log"

echo "ðŸš€ å¯åŠ¨ QwenCoder SFT è®­ç»ƒ..."
echo "ðŸ“Š å‚æ•°è®¾ç½®:"
echo "  - æ•°æ®è·¯å¾„: ${DATA_PATH}"
echo "  - é¢„è®­ç»ƒæ¨¡åž‹: ${PRETRAINED_MODEL}"
echo "  - è¾“å‡ºç›®å½•: ${OUTPUT_DIR}"
echo "ðŸ“ æ—¥å¿—æ–‡ä»¶: ${LOG_FILE}"
echo ""

# è®¾ç½®çŽ¯å¢ƒå˜é‡æ”¹å–„å†…å­˜ç®¡ç†
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
export CUDA_VISIBLE_DEVICES="0,1,2,3,4,5,6,7"

if [[ "$1" == "background" ]]; then
    echo "ðŸ”„ åŽå°å¯åŠ¨è®­ç»ƒ..."
    nohup bash ../../src/training/Qwen3-Coder/finetuning/sft/scripts/sft_qwencoder.sh \
        "${DATA_PATH}" "${PRETRAINED_MODEL}" "${OUTPUT_DIR}" \
        > "${LOG_FILE}" 2>&1 &
    
    TRAIN_PID=$!
    echo "âœ… è®­ç»ƒå·²åœ¨åŽå°å¯åŠ¨ï¼"
    echo "ðŸ†” è¿›ç¨‹ PID: ${TRAIN_PID}"
    echo "ðŸ“‹ è¿›ç¨‹çŠ¶æ€æŸ¥çœ‹: ps aux | grep ${TRAIN_PID}"
    echo "ðŸ›‘ ç»ˆæ­¢è®­ç»ƒ: kill ${TRAIN_PID}"
    echo "ðŸ”„ æŸ¥çœ‹æ—¥å¿—: tail -f ${LOG_FILE}"
    
    # ç­‰å¾…å‡ ç§’æ˜¾ç¤ºåˆå§‹æ—¥å¿—
    sleep 5
    if [[ -f "${LOG_FILE}" ]]; then
        echo ""
        echo "ðŸ“„ æœ€æ–°æ—¥å¿—å†…å®¹:"
        echo "===================="
        tail -n 10 "${LOG_FILE}"
        echo "===================="
    fi
else
    echo "ðŸ”„ å‰å°å¯åŠ¨è®­ç»ƒ..."
    bash ../../src/training/Qwen3-Coder/finetuning/sft/scripts/sft_qwencoder.sh \
        "${DATA_PATH}" "${PRETRAINED_MODEL}" "${OUTPUT_DIR}" \
        2>&1 | tee "${LOG_FILE}"
fi
